{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import math\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from mpl_toolkits.mplot3d import Axes3D  \n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from simulation_view import SimulationView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr/Projects/anfis_game_of_life/venv/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/piotr/Projects/anfis_game_of_life/venv/lib/python3.8/site-packages/stable_baselines3/common/env_checker.py:231: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def get_simulation_view():\n",
    "    return SimulationView(np.array([random.random(), random.random(), random.random()]) * 10000 + 5000, [0, 0])\n",
    "#     return SimulationView([5000, 10000, 5000], [0, 0])\n",
    "\n",
    "\n",
    "class Environment(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Environment, self).__init__()\n",
    "        self.reward_range = (-math.inf, -math.inf)\n",
    "        self.action_space = gym.spaces.Box(np.array([0]), np.array([1]), dtype=np.float32)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1e5, shape=(3,))\n",
    "        self.simulation_view = get_simulation_view()\n",
    "        self.simulation_step = 0\n",
    "        self.plot_x = np.array([])\n",
    "        self.plot_y = np.array([])\n",
    "        self.draw_plot = kwargs.get('draw_plot')\n",
    "        self.draw_plot_freq = kwargs.get('draw_plot_freq')\n",
    "\n",
    "    def step(self, action): \n",
    "        self.last_action = action\n",
    "        old_obs = list(self.simulation_view.simulation.entityCount)\n",
    "        self.simulation_view.step([action[0] * 1e5, 0])\n",
    "        obs = np.array(self.simulation_view.simulation.entityCount)\n",
    "        self.plot_x = np.append(self.plot_x, obs[0])\n",
    "        self.plot_y = np.append(self.plot_y, obs[1])\n",
    "        # reward = 1e5 - np.abs(self.simulation_view.simulation.entityCount[0] - self.simulation_view.simulation.entityCount[1])\n",
    "        # reward = self.simulation_step\n",
    "        # reward = 1\n",
    "        reward = 100 / (100 + np.sum(np.abs(obs - old_obs)))\n",
    "        # reward = 1 - min(abs(1 - np.average(np.array(obs) / np.array(old_obs))), 1)\n",
    "        # reward = 2000 - np.sum(np.abs(obs - old_obs))\n",
    "        # reward = 1 if action[0] > 0.4 and action[0] < 0.6 else 0\n",
    "        # reward = -1 if np.any(np.array(self.simulation_view.simulation.entityCount) < 100) else 1\n",
    "        # reward = 10000.0 - abs(5000 - obs[0]) - abs(5000 - obs[1])\n",
    "        # reward = (30000.0 - obs[0] - obs[1]) / 30000.0\n",
    "        done = bool(np.any(np.array(self.simulation_view.simulation.entityCount) < 1000)) \\\n",
    "               or bool(self.simulation_step > 100)\n",
    "               # or bool(np.sum(np.abs(obs - old_obs)) > (1000 - self.simulation_step) * 2)\n",
    "              \n",
    "        self.simulation_step += 1\n",
    "\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.simulation_view = get_simulation_view()\n",
    "        self.simulation_step = 0\n",
    "        self.plot_x = np.array([])\n",
    "        self.plot_y = np.array([])\n",
    "        return np.array(self.simulation_view.simulation.entityCount)\n",
    "\n",
    "    def render(self, mode='human', close=False):\n",
    "        if self.simulation_step != 0 and self.simulation_step % self.draw_plot_freq == 0:\n",
    "            self.draw_plot(self.plot_x, self.plot_y)\n",
    "        \n",
    "        \n",
    "check_env(Environment())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_empty_model():\n",
    "    env = Environment()\n",
    "    return PPO('MlpPolicy', env, clip_range=0.1, verbose=1, tensorboard_log=\"./logs/\")\n",
    "\n",
    "\n",
    "def learn_model(steps=100000, **kwargs):\n",
    "    def draw_plot(x, y):\n",
    "        ax.lines[0].set_xdata(x)\n",
    "        ax.lines[0].set_ydata(y)\n",
    "        fig.canvas.draw()\n",
    "\n",
    "    eval_callback=None\n",
    "    if kwargs.get('evaluate'):\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "        ax.plot([0, 20000], [0, 20000])\n",
    "        eval_callback = EvalCallback(Environment(draw_plot=draw_plot, draw_plot_freq=10), best_model_save_path='./logs/',\n",
    "                                     log_path='./logs/', eval_freq=kwargs.get('eval_freq', 10000), render=True)\n",
    "    \n",
    "    model = get_empty_model()\n",
    "    model.learn(total_timesteps=steps, callback=eval_callback)\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, **kwargs):\n",
    "    def draw_plot(x, y):\n",
    "        ax.lines[0].set_xdata(x)\n",
    "        ax.lines[0].set_ydata(y)\n",
    "        fig.canvas.draw()\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.plot([0, 20000], [0, 20000])\n",
    "    \n",
    "    env = Environment(draw_plot=draw_plot, draw_plot_freq=kwargs.get('draw_plot_freq', 10))\n",
    "    evaluate_policy(model, env, render=True)\n",
    "    \n",
    "\n",
    "def draw_model_surface(model):\n",
    "    def fun(x, y):\n",
    "        return list(map(lambda x: model.predict([x[0], x[1]], deterministic=True)[0][0], zip(x, y)))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    x = y = np.arange(5000, 10000, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    zs = np.array(fun(np.ravel(X), np.ravel(Y)))\n",
    "    Z = zs.reshape(X.shape)\n",
    "    ax.plot_surface(X, Y, Z)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "    if (this.ratio !== 1) {\n",
       "        fig.send_message('set_dpi_ratio', { dpi_ratio: this.ratio });\n",
       "    }\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./logs/PPO_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr/Projects/anfis_game_of_life/venv/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1000, episode_reward=0.01 +/- 0.02\n",
      "Episode length: 1.40 +/- 0.49\n",
      "New best mean reward!\n",
      "Eval num_timesteps=2000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.20 +/- 0.40\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.2      |\n",
      "|    mean_reward     | 0.00648  |\n",
      "| time/              |          |\n",
      "|    fps             | 458      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=3000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 1.40 +/- 0.49\n",
      "Eval num_timesteps=4000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 1.40 +/- 0.49\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.4          |\n",
      "|    mean_reward          | 0.00558      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 369          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013077812 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.0304       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00794     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.0325       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.40 +/- 0.49\n",
      "Eval num_timesteps=6000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 1.20 +/- 0.40\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 1.2           |\n",
      "|    mean_reward          | 0.00517       |\n",
      "| time/                   |               |\n",
      "|    fps                  | 343           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 17            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00053248566 |\n",
      "|    clip_fraction        | 0.0276        |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.42         |\n",
      "|    explained_variance   | 0.0156        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.00368      |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.000166     |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000755      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=7000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.20 +/- 0.40\n",
      "Eval num_timesteps=8000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 1.40 +/- 0.49\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.4          |\n",
      "|    mean_reward          | 0.00677      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 330          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010517215 |\n",
      "|    clip_fraction        | 0.0426       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | -0.0581      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0109      |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00195     |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 0.000418     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.20 +/- 0.40\n",
      "Eval num_timesteps=10000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.20 +/- 0.40\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 1.2           |\n",
      "|    mean_reward          | 0.00725       |\n",
      "| time/                   |               |\n",
      "|    fps                  | 329           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 31            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035910838 |\n",
      "|    clip_fraction        | 0.0391        |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.41         |\n",
      "|    explained_variance   | -0.11         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.00231      |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00183      |\n",
      "|    std                  | 0.994         |\n",
      "|    value_loss           | 0.000211      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=11000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 1.20 +/- 0.40\n",
      "Eval num_timesteps=12000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.20 +/- 0.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.2          |\n",
      "|    mean_reward          | 0.00843      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 329          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015640571 |\n",
      "|    clip_fraction        | 0.0604       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -0.166       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00371     |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    std                  | 0.99         |\n",
      "|    value_loss           | 0.000246     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1.00 +/- 0.00\n",
      "Eval num_timesteps=14000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.40 +/- 0.49\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.4          |\n",
      "|    mean_reward          | 0.00783      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 327          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013142421 |\n",
      "|    clip_fraction        | 0.0921       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -0.367       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00256      |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00166     |\n",
      "|    std                  | 0.983        |\n",
      "|    value_loss           | 0.000203     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 1.20 +/- 0.40\n",
      "Eval num_timesteps=16000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.40 +/- 0.49\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.4          |\n",
      "|    mean_reward          | 0.00827      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 326          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060040513 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | -0.125       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00354     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    std                  | 0.972        |\n",
      "|    value_loss           | 0.000321     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=17000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.40 +/- 0.49\n",
      "Eval num_timesteps=18000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 1.40 +/- 0.49\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.4          |\n",
      "|    mean_reward          | 0.00609      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 314          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 58           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036643955 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | -0.0279      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00512     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    std                  | 0.97         |\n",
      "|    value_loss           | 0.000174     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=19000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1.00 +/- 0.00\n",
      "Eval num_timesteps=20000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.60 +/- 0.49\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.6          |\n",
      "|    mean_reward          | 0.0111       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 309          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029456513 |\n",
      "|    clip_fraction        | 0.0741       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | -0.161       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00464      |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00114     |\n",
      "|    std                  | 0.956        |\n",
      "|    value_loss           | 0.000124     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=21000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1.20 +/- 0.40\n",
      "Eval num_timesteps=22000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 1.40 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.4         |\n",
      "|    mean_reward          | 0.00677     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004102437 |\n",
      "|    clip_fraction        | 0.07        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | -0.0216     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0148      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00129    |\n",
      "|    std                  | 0.949       |\n",
      "|    value_loss           | 0.000299    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=23000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.40 +/- 0.49\n",
      "Eval num_timesteps=24000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.60 +/- 0.49\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.6          |\n",
      "|    mean_reward          | 0.014        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 310          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 79           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016817367 |\n",
      "|    clip_fraction        | 0.058        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | -0.327       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00163     |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.000387    |\n",
      "|    std                  | 0.942        |\n",
      "|    value_loss           | 0.000203     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1.00 +/- 0.00\n",
      "Eval num_timesteps=26000, episode_reward=0.02 +/- 0.01\n",
      "Episode length: 1.80 +/- 0.40\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.8          |\n",
      "|    mean_reward          | 0.0194       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 312          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 85           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042241933 |\n",
      "|    clip_fraction        | 0.0906       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | -0.303       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00296      |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00114     |\n",
      "|    std                  | 0.938        |\n",
      "|    value_loss           | 0.000128     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=27000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.20 +/- 0.40\n",
      "Eval num_timesteps=28000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.40 +/- 0.49\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.4          |\n",
      "|    mean_reward          | 0.00847      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 309          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012398956 |\n",
      "|    clip_fraction        | 0.0893       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | -0.297       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.017       |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    std                  | 0.936        |\n",
      "|    value_loss           | 0.000234     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=29000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 1.20 +/- 0.40\n",
      "Eval num_timesteps=30000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1           |\n",
      "|    mean_reward          | 0.00275     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003913194 |\n",
      "|    clip_fraction        | 0.0748      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | -0.319      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00347    |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.000735   |\n",
      "|    std                  | 0.928       |\n",
      "|    value_loss           | 0.00021     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=31000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.40 +/- 0.49\n",
      "Eval num_timesteps=32000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.60 +/- 0.49\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.6          |\n",
      "|    mean_reward          | 0.0131       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 310          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 105          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019603414 |\n",
      "|    clip_fraction        | 0.0833       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | -0.241       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00163      |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00013     |\n",
      "|    std                  | 0.92         |\n",
      "|    value_loss           | 0.000198     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=33000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 1.20 +/- 0.40\n",
      "Eval num_timesteps=34000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.20 +/- 0.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.2         |\n",
      "|    mean_reward          | 0.00676     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001651959 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | -0.212      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.013      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0013     |\n",
      "|    std                  | 0.913       |\n",
      "|    value_loss           | 0.000196    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.40 +/- 0.49\n",
      "Eval num_timesteps=36000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.60 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6         |\n",
      "|    mean_reward          | 0.0142      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003905132 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | -0.122      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000338   |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00257    |\n",
      "|    std                  | 0.902       |\n",
      "|    value_loss           | 0.000158    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=37000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.20 +/- 0.40\n",
      "Eval num_timesteps=38000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 1.60 +/- 0.49\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.6          |\n",
      "|    mean_reward          | 0.0086       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 310          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077564837 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | -0.301       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0134      |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    std                  | 0.907        |\n",
      "|    value_loss           | 0.000207     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=39000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1.00 +/- 0.00\n",
      "Eval num_timesteps=40000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 1.20 +/- 0.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.2          |\n",
      "|    mean_reward          | 0.00544      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 309          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 132          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048335725 |\n",
      "|    clip_fraction        | 0.0715       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | -0.323       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00428     |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.000415    |\n",
      "|    std                  | 0.909        |\n",
      "|    value_loss           | 0.000144     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=41000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.20 +/- 0.40\n",
      "Eval num_timesteps=42000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.40 +/- 0.49\n",
      "Eval num_timesteps=43000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 1.60 +/- 0.49\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.6          |\n",
      "|    mean_reward          | 0.00899      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 305          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 140          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039706333 |\n",
      "|    clip_fraction        | 0.0878       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | -0.37        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.009        |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | 8.87e-05     |\n",
      "|    std                  | 0.897        |\n",
      "|    value_loss           | 0.000209     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=44000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.20 +/- 0.40\n",
      "Eval num_timesteps=45000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.40 +/- 0.49\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.4          |\n",
      "|    mean_reward          | 0.00816      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 304          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 148          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032989352 |\n",
      "|    clip_fraction        | 0.0997       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | -0.141       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00471      |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    std                  | 0.891        |\n",
      "|    value_loss           | 0.000143     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=46000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.40 +/- 0.49\n",
      "Eval num_timesteps=47000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1            |\n",
      "|    mean_reward          | 0.0035       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 301          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 155          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047785453 |\n",
      "|    clip_fraction        | 0.0975       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | -0.509       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00311      |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | 0.000944     |\n",
      "|    std                  | 0.89         |\n",
      "|    value_loss           | 0.000184     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=48000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.60 +/- 0.49\n",
      "Eval num_timesteps=49000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.20 +/- 0.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.2          |\n",
      "|    mean_reward          | 0.00569      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 299          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 164          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041806954 |\n",
      "|    clip_fraction        | 0.0937       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | -0.299       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00848      |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.000196    |\n",
      "|    std                  | 0.887        |\n",
      "|    value_loss           | 0.000242     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=50000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 1.20 +/- 0.40\n",
      "Eval num_timesteps=51000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.60 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6         |\n",
      "|    mean_reward          | 0.00926     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 172         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006570479 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | -0.258      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00384    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00103    |\n",
      "|    std                  | 0.888       |\n",
      "|    value_loss           | 0.000161    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=52000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 1.40 +/- 0.49\n",
      "Eval num_timesteps=53000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1.20 +/- 0.40\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 1.2           |\n",
      "|    mean_reward          | 0.00423       |\n",
      "| time/                   |               |\n",
      "|    fps                  | 297           |\n",
      "|    iterations           | 26            |\n",
      "|    time_elapsed         | 179           |\n",
      "|    total_timesteps      | 53248         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028481084 |\n",
      "|    clip_fraction        | 0.0866        |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.3          |\n",
      "|    explained_variance   | -0.304        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00138       |\n",
      "|    n_updates            | 250           |\n",
      "|    policy_gradient_loss | -0.000464     |\n",
      "|    std                  | 0.883         |\n",
      "|    value_loss           | 0.000167      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=54000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 1.40 +/- 0.49\n",
      "Eval num_timesteps=55000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 1.20 +/- 0.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.2         |\n",
      "|    mean_reward          | 0.00554     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 295         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 186         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003852208 |\n",
      "|    clip_fraction        | 0.0916      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | -0.502      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00767    |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | 0.000101    |\n",
      "|    std                  | 0.889       |\n",
      "|    value_loss           | 0.000147    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=56000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.40 +/- 0.49\n",
      "Eval num_timesteps=57000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.40 +/- 0.49\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.4          |\n",
      "|    mean_reward          | 0.0106       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 294          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 194          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025430229 |\n",
      "|    clip_fraction        | 0.0948       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | -0.661       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00404      |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00143     |\n",
      "|    std                  | 0.887        |\n",
      "|    value_loss           | 0.000124     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=58000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 1.60 +/- 0.49\n",
      "Eval num_timesteps=59000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.60 +/- 0.49\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.6          |\n",
      "|    mean_reward          | 0.013        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 293          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 202          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011007709 |\n",
      "|    clip_fraction        | 0.0988       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | -0.777       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00123     |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | 0.00206      |\n",
      "|    std                  | 0.882        |\n",
      "|    value_loss           | 0.000117     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.60 +/- 0.49\n",
      "Eval num_timesteps=61000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 1.40 +/- 0.49\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.4          |\n",
      "|    mean_reward          | 0.00552      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 293          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 209          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056243865 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | -1.13        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0144       |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | 0.00016      |\n",
      "|    std                  | 0.878        |\n",
      "|    value_loss           | 0.000162     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=62000, episode_reward=0.02 +/- 0.02\n",
      "Episode length: 1.40 +/- 0.49\n",
      "Eval num_timesteps=63000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.80 +/- 0.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.8         |\n",
      "|    mean_reward          | 0.0137      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 294         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 215         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005451612 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | -0.668      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00221    |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | 0.000769    |\n",
      "|    std                  | 0.88        |\n",
      "|    value_loss           | 0.000191    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1.00 +/- 0.00\n",
      "Eval num_timesteps=65000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1.20 +/- 0.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.2          |\n",
      "|    mean_reward          | 0.00417      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 291          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 224          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029183105 |\n",
      "|    clip_fraction        | 0.0927       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | -0.472       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0264       |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | 0.000731     |\n",
      "|    std                  | 0.882        |\n",
      "|    value_loss           | 0.000264     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=66000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1.20 +/- 0.40\n",
      "Eval num_timesteps=67000, episode_reward=0.02 +/- 0.01\n",
      "Episode length: 1.80 +/- 0.40\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.8         |\n",
      "|    mean_reward          | 0.021       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 232         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009205111 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | -0.273      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00362    |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | 0.000448    |\n",
      "|    std                  | 0.873       |\n",
      "|    value_loss           | 0.000148    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=68000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.60 +/- 0.49\n",
      "Eval num_timesteps=69000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1.20 +/- 0.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.2          |\n",
      "|    mean_reward          | 0.00466      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 289          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 240          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043831263 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | -0.574       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0104      |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | 0.00254      |\n",
      "|    std                  | 0.858        |\n",
      "|    value_loss           | 0.000169     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.40 +/- 0.49\n",
      "Eval num_timesteps=71000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.20 +/- 0.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.2          |\n",
      "|    mean_reward          | 0.00591      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 288          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 248          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029337294 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | -0.629       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00114     |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | 0.00378      |\n",
      "|    std                  | 0.845        |\n",
      "|    value_loss           | 0.00011      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=72000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.20 +/- 0.40\n",
      "Eval num_timesteps=73000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.20 +/- 0.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.2          |\n",
      "|    mean_reward          | 0.0077       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 287          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 256          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054922453 |\n",
      "|    clip_fraction        | 0.144        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | -0.678       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00365      |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | 0.0014       |\n",
      "|    std                  | 0.833        |\n",
      "|    value_loss           | 0.000233     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=74000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1.00 +/- 0.00\n",
      "Eval num_timesteps=75000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 1.60 +/- 0.49\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.6          |\n",
      "|    mean_reward          | 0.00744      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 287          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 263          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029247836 |\n",
      "|    clip_fraction        | 0.0998       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | -0.356       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00605     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | 0.00106      |\n",
      "|    std                  | 0.835        |\n",
      "|    value_loss           | 0.000181     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=76000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 1.40 +/- 0.49\n",
      "Eval num_timesteps=77000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1            |\n",
      "|    mean_reward          | 0.00369      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 286          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 271          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024123585 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | -0.367       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0016      |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | 0.00174      |\n",
      "|    std                  | 0.822        |\n",
      "|    value_loss           | 9.55e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=78000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.60 +/- 0.49\n",
      "Eval num_timesteps=79000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.60 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6         |\n",
      "|    mean_reward          | 0.00989     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 279         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007401497 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | -0.511      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00413    |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | 0.00298     |\n",
      "|    std                  | 0.813       |\n",
      "|    value_loss           | 0.000115    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.20 +/- 0.40\n",
      "Eval num_timesteps=81000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.40 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.4         |\n",
      "|    mean_reward          | 0.0103      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 286         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003982205 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | -0.027      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00809    |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | 0.00163     |\n",
      "|    std                  | 0.811       |\n",
      "|    value_loss           | 0.000134    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=82000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1.00 +/- 0.00\n",
      "Eval num_timesteps=83000, episode_reward=0.02 +/- 0.01\n",
      "Episode length: 1.80 +/- 0.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.8          |\n",
      "|    mean_reward          | 0.0173       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 287          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 292          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049535325 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | -0.864       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00304     |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | 0.000373     |\n",
      "|    std                  | 0.805        |\n",
      "|    value_loss           | 0.000169     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=84000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.40 +/- 0.49\n",
      "Eval num_timesteps=85000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.40 +/- 0.49\n",
      "Eval num_timesteps=86000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 1.20 +/- 0.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.2          |\n",
      "|    mean_reward          | 0.00559      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 287          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 298          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049789147 |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | -0.587       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0099      |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | 0.00253      |\n",
      "|    std                  | 0.803        |\n",
      "|    value_loss           | 0.000139     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=87000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1.00 +/- 0.00\n",
      "Eval num_timesteps=88000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.20 +/- 0.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.2         |\n",
      "|    mean_reward          | 0.00665     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 306         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007831295 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | -0.48       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0041     |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | 0.0057      |\n",
      "|    std                  | 0.795       |\n",
      "|    value_loss           | 0.00012     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=89000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.60 +/- 0.49\n",
      "Eval num_timesteps=90000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.20 +/- 0.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.2         |\n",
      "|    mean_reward          | 0.00866     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 314         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004340004 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | -0.288      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00129    |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | 0.00416     |\n",
      "|    std                  | 0.798       |\n",
      "|    value_loss           | 0.000115    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=91000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.80 +/- 0.40\n",
      "Eval num_timesteps=92000, episode_reward=0.02 +/- 0.02\n",
      "Episode length: 1.40 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.4         |\n",
      "|    mean_reward          | 0.0153      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 323         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008076487 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | -0.0895     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00442    |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00119    |\n",
      "|    std                  | 0.799       |\n",
      "|    value_loss           | 0.000127    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=93000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.80 +/- 0.40\n",
      "Eval num_timesteps=94000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.40 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.4         |\n",
      "|    mean_reward          | 0.00746     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 331         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008125197 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | -0.214      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00423     |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | 0.00325     |\n",
      "|    std                  | 0.789       |\n",
      "|    value_loss           | 9.39e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=95000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.40 +/- 0.49\n",
      "Eval num_timesteps=96000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.60 +/- 0.49\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.6          |\n",
      "|    mean_reward          | 0.0149       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 283          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 338          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035896865 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | -0.0556      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0181       |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | 0.00244      |\n",
      "|    std                  | 0.791        |\n",
      "|    value_loss           | 9.91e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=97000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1.00 +/- 0.00\n",
      "Eval num_timesteps=98000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.40 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.4         |\n",
      "|    mean_reward          | 0.00985     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 346         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006240328 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | -0.527      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0111      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | 0.00311     |\n",
      "|    std                  | 0.782       |\n",
      "|    value_loss           | 0.000258    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=99000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.40 +/- 0.49\n",
      "Eval num_timesteps=100000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 1.40 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.4         |\n",
      "|    mean_reward          | 0.0142      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 353         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010235969 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | -0.374      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.013       |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | 0.00615     |\n",
      "|    std                  | 0.778       |\n",
      "|    value_loss           | 0.000102    |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = learn_model(100000, evaluate=True, eval_freq=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"logs/best_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_model_surface(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "destilation",
   "language": "python",
   "name": "destilation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
